{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトルストアでの利用\n",
    "1. FAISSに格納\n",
    "2. FAISSから取得\n",
    "3. FAISSでベクトル検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain_community.vectorstores import Pinecone # ほかのベクトルストアもコード変更なく同様に使える\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PDFデータ読み込み\n",
    "pdf_page = PdfReader(\"./data/llm.pdf\")\n",
    "text = \"\"\n",
    "# PDFデータをテキストに変換\n",
    "for page in pdf_page.pages:\n",
    "    text += page.extract_text()\n",
    "print(text[:100]) # 先頭100文字を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. データをチャンクに小分けにする\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # チャンクの最大文字数\n",
    "    chunk_overlap=100   # チャンク間の重複文字数\n",
    ")\n",
    "docs = text_splitter.split_text(text) # テキストをチャンクに分割\n",
    "docs_chunks = text_splitter.create_documents(docs) # チャンクをドキュメントに変換\n",
    "print(\"Docサイズ\", len(docs_chunks))\n",
    "print(\"型\", type(docs_chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. OpenAIのembeddingモデル取得\n",
    "openAI_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openAI_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "\n",
    "embeddings = None\n",
    "if openAI_key != \"\" :\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "      api_key=openAI_key,\n",
    "      azure_deployment=\"text-embedding-ada-002\",\n",
    "      # openai_api_versiton=\"2024-10-21\",\n",
    "      azure_endpoint=openAI_endpoint\n",
    "    )\n",
    "else:\n",
    "    print(\"EmbeddingのAPIKeyを設定してください\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ベクトル化\n",
    "# 一括でベクトル化する場合\n",
    "# faiss_db = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "\n",
    "# プログレスバーを表示しながらベクトル化\n",
    "faiss_db = None\n",
    "with tqdm(total=len(docs_chunks), desc=\"documents 抽出\") as pbar:\n",
    "    for d in docs_chunks:\n",
    "        if faiss_db:\n",
    "            faiss_db.add_documents([d])\n",
    "        else:\n",
    "            faiss_db = FAISS.from_documents([d], embeddings)\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ベクトル化データを保存\n",
    "faiss_db.save_local(\"./db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化データを読み込み\n",
    "vectorstore  = FAISS.load_local(\n",
    "    \"./db\", # ベクトル化データの保存先\n",
    "    embeddings, # ベクトル化モデル\n",
    "    allow_dangerous_deserialization=True # デシリアライズを許可 (デフォルトはFalse)でセキュリティを向上\n",
    ")\n",
    "\n",
    "# retrieverを取得\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類似文書の取得\n",
    "similar_docs = retriever.get_relevant_documents(\"言語モデル\", k=3)\n",
    "# similar_docs = retriever.invoke(\"言語モデル\", k=3)\n",
    "\n",
    "# 類似文書を表示\n",
    "for doc in similar_docs:\n",
    "    print(doc)\n",
    "    print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
